import streamlit as st
import re
import io
import zipfile
import os
from docx import Document

# --- è¨­å®š: é™¤å¤–ã—ãŸã„å˜èªãƒªã‚¹ãƒˆï¼ˆã“ã“ã«å«ã¾ã‚Œã‚‹å˜èªã¯åå‰ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰ ---
IGNORE_LIST = [
    'å‚åŠ è€…', 'è©±è€…', 'è©³ç´°', 'ã¾ã¨ã‚', 'æ—¥æ™‚', 'Source', 'source', 'æ–‡å­—èµ·ã“ã—', 'ãƒ¡ãƒ¢', 'é•·ã•', 'Time', 'Unknown',
    'ENG', 'JPN', 'ENG/JPN', 'ENG_JPN', 'JST', 'Gemini', 'ã«ã‚ˆã‚‹ãƒ¡ãƒ¢', 'ã®ã‚³ãƒ”ãƒ¼', 'æ¨™æº–', 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼', 'å¯¾è±¡è€…',
    'ä¼šè­°ã®éŒ²ç”»', 'æ‹›å¾…æ¸ˆã¿', 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«', 'mp4', 'm4a', 'wav', 'docx', 'txt', 'pdf'
]

def is_valid_name(name):
    """åå‰ã¨ã—ã¦é©åˆ‡ã‹åˆ¤å®šã™ã‚‹"""
    clean_name = name.strip()
    if not clean_name:
        return False
    if len(clean_name) <= 1:
        return False
    if clean_name.isdigit(): # æ•°å­—ã ã‘ã¯NG
        return False
    # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–ï¼‰
    for ignore in IGNORE_LIST:
        if ignore.lower() == clean_name.lower():
            return False
        # "2025/10/27" ã®ã‚ˆã†ãªæ—¥ä»˜ã£ã½ã„ã‚‚ã®ã‚‚é™¤å¤–
        if re.search(r'\d', clean_name) and re.search(r'[\/\-_]', clean_name):
            return False
    return True

def extract_names(text, filename=""):
    """ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰åå‰å€™è£œã‚’ã™ã¹ã¦æŠ½å‡ºã™ã‚‹"""
    potential_names = set()

    # 1. æœ¬æ–‡ä¸­ã® 'åå‰: ' ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: "æœ¨åŸè‰¯æ¨¹: " "Ayaka Takafuji: ")
    pattern_colon = r'(?:^|\n)(?:\[.*?\]\s*)?([^\n\rï¼š:]{2,20}?)\s*[:ï¼š]'
    matches_colon = re.findall(pattern_colon, text)
    potential_names.update(matches_colon)

    # 2. ãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ‹¬å¼§å†…ã®æ–‡å­—åˆ— (ä¾‹: "(XIAOHUI SU)" )
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’é™¤ã
    base_name = os.path.splitext(filename)[0]
    # ãƒ•ã‚¡ã‚¤ãƒ«åã¨æœ¬æ–‡ã®å…ˆé ­500æ–‡å­—ã‚’å¯¾è±¡ã«æ‹¬å¼§ã®ä¸­èº«ã‚’æ¢ã™
    search_target = base_name + "\n" + text[:500]
    
    # ä¸¸æ‹¬å¼§ ( ) ã¾ãŸã¯ï¼ˆ ï¼‰ã®ä¸­èº«ã‚’æŠ½å‡º
    pattern_bracket = r'[ï¼ˆ\(]([^ï¼‰\)\n\r]{2,20}?)[ï¼‰\)]'
    matches_bracket = re.findall(pattern_bracket, search_target)
    potential_names.update(matches_bracket)

    # 3. ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ "H.Sakai" ã®ã‚ˆã†ãªè‹±å­—åã‚‚æ‹¾ã†
    # (ç©ºç™½åŒºåˆ‡ã‚Šã‚„ãƒ‰ãƒƒãƒˆã‚’å«ã‚€è‹±å­—ã®å¡Š)
    if "H.Sakai" in search_target: # ç‰¹ã«æŒ‡å®šãŒã‚ã£ãŸãŸã‚æ˜ç¤ºçš„ã«ãƒã‚§ãƒƒã‚¯
        potential_names.add("H.Sakai")

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    unique_names = set()
    for name in potential_names:
        if is_valid_name(name):
            unique_names.add(name.strip())
    
    # åå‰ãŒé•·ã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆ"ç”°ä¸­å¤ªéƒ" ã‚’ "ç”°ä¸­" ã‚ˆã‚Šå…ˆã«ç½®æ›ã™ã‚‹ãŸã‚ï¼‰
    return sorted(list(unique_names), key=len, reverse=True)

def generate_name_map(names):
    """åå‰ãƒªã‚¹ãƒˆã‹ã‚‰ç½®æ›ãƒãƒƒãƒ—(Speaker_A...)ã‚’ä½œæˆ"""
    name_map = {}
    chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    for i, name in enumerate(names):
        replacement = f"Speaker_{chars[i % len(chars)]}"
        if i >= len(chars):
            replacement += str(i)
        name_map[name] = replacement
    return name_map

def process_content(content, filename):
    """ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å—ã‘å–ã‚Šã€ç½®æ›å¾Œã®å†…å®¹ã¨æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã™"""
    # åå‰æŠ½å‡º
    names = extract_names(content, filename)
    name_map = generate_name_map(names)

    # æœ¬æ–‡ã®ç½®æ›
    new_content = content
    for original, new in name_map.items():
        new_content = new_content.replace(original, new)

    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç½®æ›
    name_part, ext = os.path.splitext(filename)
    new_name_part = name_part
    for original, new in name_map.items():
        # ãƒ•ã‚¡ã‚¤ãƒ«åå†…ã®åå‰ã‚’ç½®æ›
        if original in new_name_part:
            new_name_part = new_name_part.replace(original, new)
    
    new_filename = new_name_part + ext
    return new_filename, new_content, name_map

# --- ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ©ãƒƒãƒ‘ãƒ¼ ---
def process_text_file(file_obj):
    try:
        bytes_data = file_obj.getvalue()
        try:
            content = bytes_data.decode('utf-8')
        except UnicodeDecodeError:
            content = bytes_data.decode('cp932', errors='ignore')
    except:
        return None, None
    
    new_filename, new_content, _ = process_content(content, file_obj.name)
    return new_filename, new_content.encode('utf-8')

def process_docx_file(file_obj):
    try:
        doc = Document(file_obj)
    except:
        return None, None

    # å…¨æ–‡å–å¾—
    full_text_list = []
    for para in doc.paragraphs:
        full_text_list.append(para.text)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                full_text_list.append(cell.text)
    
    full_text_joined = "\n".join(full_text_list)
    
    # åå‰æŠ½å‡ºã¨ãƒãƒƒãƒ—ä½œæˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚‚è€ƒæ…®ï¼‰
    names = extract_names(full_text_joined, file_obj.name)
    name_map = generate_name_map(names)

    # ç½®æ›å®Ÿè¡Œ
    # 1. æ®µè½
    for para in doc.paragraphs:
        for original, new in name_map.items():
            if original in para.text:
                para.text = para.text.replace(original, new)
    # 2. ãƒ†ãƒ¼ãƒ–ãƒ«
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for original, new in name_map.items():
                    if original in cell.text:
                        cell.text = cell.text.replace(original, new)

    # ãƒ•ã‚¡ã‚¤ãƒ«åç½®æ›
    name_part, ext = os.path.splitext(file_obj.name)
    new_name_part = name_part
    for original, new in name_map.items():
        if original in new_name_part:
            new_name_part = new_name_part.replace(original, new)
    new_filename = new_name_part + ext

    # ä¿å­˜
    output_stream = io.BytesIO()
    doc.save(output_stream)
    return new_filename, output_stream.getvalue()

# --- ã‚¢ãƒ—ãƒªç”»é¢ ---
st.title("ğŸ•µï¸ æ–‡å­—èµ·ã“ã—åŒ¿ååŒ–ãƒ„ãƒ¼ãƒ« v2")
st.markdown("""
ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã§åŒ¿ååŒ–ã—ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã«å«ã¾ã‚Œã‚‹åå‰ã‚‚æ¤œå‡ºã—ã¾ã™ã€‚
* ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (.txt, .md, .csv)
* Wordãƒ•ã‚¡ã‚¤ãƒ« (.docx)
""")

uploaded_files = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True)

if uploaded_files:
    if st.button(f"{len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†é–‹å§‹"):
        progress_bar = st.progress(0)
        zip_buffer = io.BytesIO()
        processed_count = 0
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, file_obj in enumerate(uploaded_files):
                filename = file_obj.name
                ext = os.path.splitext(filename)[1].lower()
                
                if ext == '.docx':
                    new_name, new_data = process_docx_file(file_obj)
                else:
                    new_name, new_data = process_text_file(file_obj)
                
                if new_name and new_data:
                    zip_file.writestr(new_name, new_data)
                    processed_count += 1
                
                progress_bar.progress((i + 1) / len(uploaded_files))
        
        st.success(f"å®Œäº†ï¼ {processed_count} / {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿")
        st.download_button("ğŸ“¦ ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buffer.getvalue(), "anonymized_v2.zip", "application/zip")

import streamlit as st
import re
import io
import zipfile
import os
from docx import Document

# --- è¨­å®š: é™¤å¤–ã—ãŸã„å˜èªãƒªã‚¹ãƒˆ ---
IGNORE_LIST = [
    'å‚åŠ è€…', 'è©±è€…', 'è©³ç´°', 'ã¾ã¨ã‚', 'æ—¥æ™‚', 'Source', 'source', 'æ–‡å­—èµ·ã“ã—', 'ãƒ¡ãƒ¢', 'é•·ã•', 'Time', 'Unknown',
    'ENG', 'JPN', 'ENG/JPN', 'ENG_JPN', 'JST', 'Gemini', 'ã«ã‚ˆã‚‹ãƒ¡ãƒ¢', 'ã®ã‚³ãƒ”ãƒ¼', 'æ¨™æº–', 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼', 'å¯¾è±¡è€…',
    'ä¼šè­°ã®éŒ²ç”»', 'æ‹›å¾…æ¸ˆã¿', 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«', 'mp4', 'm4a', 'wav', 'docx', 'txt', 'pdf', 'com', 'jp', 'ac'
]

def is_valid_name(name):
    """åå‰ã¨ã—ã¦é©åˆ‡ã‹åˆ¤å®šã™ã‚‹"""
    clean_name = name.strip()
    if not clean_name:
        return False
    if len(clean_name) <= 1:
        return False
    if clean_name.isdigit(): 
        return False
    # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–ï¼‰
    for ignore in IGNORE_LIST:
        if ignore.lower() == clean_name.lower():
            return False
        # æ—¥ä»˜å½¢å¼ã®é™¤å¤–
        if re.search(r'\d', clean_name) and re.search(r'[\/\-_]', clean_name):
            # ãŸã ã—ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã«å«ã¾ã‚Œã‚‹æ•°å­—ã‚„è¨˜å·ã¯è¨±å¯ã—ãŸã„ã®ã§ã€
            # @ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯æ—¥ä»˜åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æœ‰åŠ¹ã¨ã™ã‚‹
            if '@' not in clean_name:
                return False
    return True

def extract_names(text, filename=""):
    """ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰åå‰ãƒ»ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å€™è£œã‚’ã™ã¹ã¦æŠ½å‡ºã™ã‚‹"""
    potential_names = set()

    # 1. ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æŠ½å‡º (æœ€å„ªå…ˆ)
    # æœ¬æ–‡ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¢ãƒ‰å½¢å¼ã‚’æ¢ã™
    pattern_email = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    matches_email_text = re.findall(pattern_email, text)
    matches_email_file = re.findall(pattern_email, filename)
    potential_names.update(matches_email_text)
    potential_names.update(matches_email_file)

    # 2. æœ¬æ–‡ä¸­ã® 'åå‰: ' ãƒ‘ã‚¿ãƒ¼ãƒ³
    pattern_colon = r'(?:^|\n)(?:\[.*?\]\s*)?([^\n\rï¼š:]{2,20}?)\s*[:ï¼š]'
    matches_colon = re.findall(pattern_colon, text)
    potential_names.update(matches_colon)

    # 3. ãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ‹¬å¼§å†…ã®æ–‡å­—åˆ—
    base_name = os.path.splitext(filename)[0]
    search_target = base_name + "\n" + text[:500] 
    pattern_bracket = r'[ï¼ˆ\(]([^ï¼‰\)\n\r]{2,20}?)[ï¼‰\)]'
    matches_bracket = re.findall(pattern_bracket, search_target)
    potential_names.update(matches_bracket)

    # 4. ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®è£œè¶³
    if "H.Sakai" in search_target:
        potential_names.add("H.Sakai")

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    unique_names = set()
    for name in potential_names:
        if is_valid_name(name):
            unique_names.add(name.strip())
    
    # åå‰ãŒé•·ã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé‡è¦ï¼šãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ã‚ˆã†ã«é•·ã„æ–‡å­—åˆ—ã‚’å…ˆã«ç½®æ›ã™ã‚‹ãŸã‚ï¼‰
    return sorted(list(unique_names), key=len, reverse=True)

def generate_name_map(names):
    """åå‰ãƒªã‚¹ãƒˆã‹ã‚‰ç½®æ›ãƒãƒƒãƒ—(Speaker_A...)ã‚’ä½œæˆ"""
    name_map = {}
    chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    for i, name in enumerate(names):
        replacement = f"Speaker_{chars[i % len(chars)]}"
        if i >= len(chars):
            replacement += str(i)
        name_map[name] = replacement
    return name_map

def process_content(content, filename):
    """ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å—ã‘å–ã‚Šã€ç½®æ›å¾Œã®å†…å®¹ã¨æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã™"""
    names = extract_names(content, filename)
    name_map = generate_name_map(names)

    # æœ¬æ–‡ã®ç½®æ›
    new_content = content
    for original, new in name_map.items():
        new_content = new_content.replace(original, new)

    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç½®æ›
    name_part, ext = os.path.splitext(filename)
    new_name_part = name_part
    for original, new in name_map.items():
        if original in new_name_part:
            new_name_part = new_name_part.replace(original, new)
    
    new_filename = new_name_part + ext
    return new_filename, new_content, name_map

# --- ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ©ãƒƒãƒ‘ãƒ¼ ---
def process_text_file(file_obj):
    try:
        bytes_data = file_obj.getvalue()
        try:
            content = bytes_data.decode('utf-8')
        except UnicodeDecodeError:
            content = bytes_data.decode('cp932', errors='ignore')
    except:
        return None, None
    
    new_filename, new_content, _ = process_content(content, file_obj.name)
    return new_filename, new_content.encode('utf-8')

def process_docx_file(file_obj):
    try:
        doc = Document(file_obj)
    except:
        return None, None

    # å…¨æ–‡å–å¾—
    full_text_list = []
    for para in doc.paragraphs:
        full_text_list.append(para.text)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                full_text_list.append(cell.text)
    
    full_text_joined = "\n".join(full_text_list)
    
    names = extract_names(full_text_joined, file_obj.name)
    name_map = generate_name_map(names)

    # ç½®æ›å®Ÿè¡Œ
    for para in doc.paragraphs:
        for original, new in name_map.items():
            if original in para.text:
                para.text = para.text.replace(original, new)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for original, new in name_map.items():
                    if original in cell.text:
                        cell.text = cell.text.replace(original, new)

    name_part, ext = os.path.splitext(file_obj.name)
    new_name_part = name_part
    for original, new in name_map.items():
        if original in new_name_part:
            new_name_part = new_name_part.replace(original, new)
    new_filename = new_name_part + ext

    output_stream = io.BytesIO()
    doc.save(output_stream)
    return new_filename, output_stream.getvalue()

# --- ã‚¢ãƒ—ãƒªç”»é¢ ---
st.title("ğŸ•µï¸ æ–‡å­—èµ·ã“ã—åŒ¿ååŒ–ãƒ„ãƒ¼ãƒ« v3")
st.markdown("""
ä»¥ä¸‹ã®æƒ…å ±ã‚’ä¸€æ‹¬ã§ `Speaker_X` ç­‰ã«å¤‰æ›ã—ã¾ã™ã€‚
* **åå‰**ï¼ˆæœ¬æ–‡ä¸­ã®ã€Œåå‰:ã€ã‚„ãƒ•ã‚¡ã‚¤ãƒ«åã®æ‹¬å¼§å†…ï¼‰
* **ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹**ï¼ˆæœ¬æ–‡ã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã«å«ã¾ã‚Œã‚‹ã‚‚ã®ï¼‰

å¯¾å¿œå½¢å¼: `.txt`, `.md`, `.csv`, `.docx`
""")

uploaded_files = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True)

if uploaded_files:
    if st.button(f"{len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†é–‹å§‹"):
        progress_bar = st.progress(0)
        zip_buffer = io.BytesIO()
        processed_count = 0
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, file_obj in enumerate(uploaded_files):
                filename = file_obj.name
                ext = os.path.splitext(filename)[1].lower()
                
                if ext == '.docx':
                    new_name, new_data = process_docx_file(file_obj)
                else:
                    new_name, new_data = process_text_file(file_obj)
                
                if new_name and new_data:
                    zip_file.writestr(new_name, new_data)
                    processed_count += 1
                
                progress_bar.progress((i + 1) / len(uploaded_files))
        
        st.success(f"å®Œäº†ï¼ {processed_count} / {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿")
        st.download_button("ğŸ“¦ ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buffer.getvalue(), "anonymized_v3.zip", "application/zip")

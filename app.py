import streamlit as st
import re
import io
import zipfile
import os
from docx import Document

# --- è¨­å®š: é™¤å¤–ã—ãŸã„å˜èªãƒªã‚¹ãƒˆ ---
IGNORE_LIST = [
    'å‚åŠ è€…', 'è©±è€…', 'è©³ç´°', 'ã¾ã¨ã‚', 'æ—¥æ™‚', 'Source', 'source', 'æ–‡å­—èµ·ã“ã—', 'ãƒ¡ãƒ¢', 'é•·ã•', 'Time', 'Unknown',
    'ENG', 'JPN', 'ENG/JPN', 'ENG_JPN', 'JST', 'Gemini', 'ã«ã‚ˆã‚‹ãƒ¡ãƒ¢', 'ã®ã‚³ãƒ”ãƒ¼', 'æ¨™æº–', 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼', 'å¯¾è±¡è€…',
    'ä¼šè­°ã®éŒ²ç”»', 'æ‹›å¾…æ¸ˆã¿', 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«', 'mp4', 'm4a', 'wav', 'docx', 'txt', 'pdf', 'com', 'jp', 'ac',
    'Speaker', 'ç­‘æ³¢å¤§å­¦'
]

def is_valid_name(name):
    """åå‰ã¨ã—ã¦é©åˆ‡ã‹åˆ¤å®šã™ã‚‹"""
    clean_name = name.strip()
    if not clean_name:
        return False
    if len(clean_name) <= 1:
        return False
    if clean_name.isdigit(): 
        return False
    
    # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–ï¼‰
    for ignore in IGNORE_LIST:
        # å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        if ignore.lower() == clean_name.lower():
            return False
        # Speaker_A ã®ã‚ˆã†ãªæ—¢å­˜ã®ç½®æ›ãƒãƒ¼ãƒ ã‚‚é™¤å¤–
        if "speaker" in clean_name.lower():
            return False
            
        # æ—¥ä»˜å½¢å¼ã®é™¤å¤– (æ•°å­—ã¨è¨˜å·ã®æ··åœ¨)
        if re.search(r'\d', clean_name) and re.search(r'[\/\-_]', clean_name):
            if '@' not in clean_name: # ãƒ¡ã‚¢ãƒ‰ã¯è¨±å¯
                return False
    return True

def extract_names(text, filename=""):
    """ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰åå‰ãƒ»ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å€™è£œã‚’ã™ã¹ã¦æŠ½å‡ºã™ã‚‹"""
    potential_names = set()

    # 1. ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ä»˜ãã®åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ (æœ€å„ªå…ˆè¿½åŠ )
    # ä¾‹: R.Okuzumi, X.Su, H.Sakai
    # [å¤§æ–‡å­—1æ–‡å­—] [ãƒ‰ãƒƒãƒˆ] [å¤§æ–‡å­—] [è‹±å­—1æ–‡å­—ä»¥ä¸Š]
    pattern_initial = r'\b[A-Z]\.[A-Z][a-zA-Z]+'
    matches_initial_text = re.findall(pattern_initial, text)
    matches_initial_file = re.findall(pattern_initial, filename)
    potential_names.update(matches_initial_text)
    potential_names.update(matches_initial_file)

    # 2. ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
    pattern_email = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    matches_email_text = re.findall(pattern_email, text)
    matches_email_file = re.findall(pattern_email, filename)
    potential_names.update(matches_email_text)
    potential_names.update(matches_email_file)

    # 3. æœ¬æ–‡ä¸­ã® 'åå‰: ' ãƒ‘ã‚¿ãƒ¼ãƒ³
    pattern_colon = r'(?:^|\n)(?:\[.*?\]\s*)?([^\n\rï¼š:]{2,20}?)\s*[:ï¼š]'
    matches_colon = re.findall(pattern_colon, text)
    potential_names.update(matches_colon)

    # 4. ãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ‹¬å¼§å†…ã®æ–‡å­—åˆ—
    # æ‹¬å¼§ã®ä¸­èº«ã‚’å–ã‚Šå‡ºã—ã€ã•ã‚‰ã« " - " ç­‰ã§åˆ†å‰²ã—ã¦è©•ä¾¡ã™ã‚‹
    base_name = os.path.splitext(filename)[0]
    search_target = base_name + "\n" + text[:500] 
    pattern_bracket = r'[ï¼ˆ\(]([^ï¼‰\)\n\r]+?)[ï¼‰\)]'
    matches_bracket = re.findall(pattern_bracket, search_target)
    
    for content in matches_bracket:
        # æ‹¬å¼§ã®ä¸­èº«ã‚’åŒºåˆ‡ã‚Šæ–‡å­—ã§åˆ†å‰²ã—ã¦ã¿ã‚‹ (ä¾‹: "Speaker_C - R.Okuzumi")
        parts = re.split(r'[\s\-_/]+', content)
        # åˆ†å‰²å‰ã®å…¨ä½“ã‚‚å€™è£œã«å…¥ã‚Œã‚‹
        potential_names.add(content)
        # åˆ†å‰²å¾Œã®ãƒ‘ãƒ¼ãƒ„ã‚‚å€™è£œã«å…¥ã‚Œã‚‹
        for p in parts:
            potential_names.add(p)

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    unique_names = set()
    for name in potential_names:
        # è¨˜å·ã‚’é™¤å»ã—ã¦ç´”ç²‹ãªåå‰éƒ¨åˆ†ã ã‘ã§ãƒã‚§ãƒƒã‚¯
        clean = name.strip(" -_")
        if is_valid_name(clean):
            unique_names.add(clean)
    
    # åå‰ãŒé•·ã„é †ã«ã‚½ãƒ¼ãƒˆ
    return sorted(list(unique_names), key=len, reverse=True)

def generate_name_map(names):
    """åå‰ãƒªã‚¹ãƒˆã‹ã‚‰ç½®æ›ãƒãƒƒãƒ—(Speaker_A...)ã‚’ä½œæˆ"""
    name_map = {}
    chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    for i, name in enumerate(names):
        replacement = f"Speaker_{chars[i % len(chars)]}"
        if i >= len(chars):
            replacement += str(i)
        name_map[name] = replacement
    return name_map

def process_content(content, filename):
    names = extract_names(content, filename)
    name_map = generate_name_map(names)

    # æœ¬æ–‡ã®ç½®æ›
    new_content = content
    for original, new in name_map.items():
        new_content = new_content.replace(original, new)

    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç½®æ›
    name_part, ext = os.path.splitext(filename)
    new_name_part = name_part
    for original, new in name_map.items():
        if original in new_name_part:
            new_name_part = new_name_part.replace(original, new)
    
    new_filename = new_name_part + ext
    return new_filename, new_content, name_map

# --- ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ©ãƒƒãƒ‘ãƒ¼ ---
def process_text_file(file_obj):
    try:
        bytes_data = file_obj.getvalue()
        try:
            content = bytes_data.decode('utf-8')
        except UnicodeDecodeError:
            content = bytes_data.decode('cp932', errors='ignore')
    except:
        return None, None
    
    new_filename, new_content, _ = process_content(content, file_obj.name)
    return new_filename, new_content.encode('utf-8')

def process_docx_file(file_obj):
    try:
        doc = Document(file_obj)
    except:
        return None, None

    # å…¨æ–‡å–å¾—
    full_text_list = []
    for para in doc.paragraphs:
        full_text_list.append(para.text)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                full_text_list.append(cell.text)
    
    full_text_joined = "\n".join(full_text_list)
    
    names = extract_names(full_text_joined, file_obj.name)
    name_map = generate_name_map(names)

    # ç½®æ›å®Ÿè¡Œ
    for para in doc.paragraphs:
        for original, new in name_map.items():
            if original in para.text:
                para.text = para.text.replace(original, new)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for original, new in name_map.items():
                    if original in cell.text:
                        cell.text = cell.text.replace(original, new)

    name_part, ext = os.path.splitext(file_obj.name)
    new_name_part = name_part
    for original, new in name_map.items():
        if original in new_name_part:
            new_name_part = new_name_part.replace(original, new)
    new_filename = new_name_part + ext

    output_stream = io.BytesIO()
    doc.save(output_stream)
    return new_filename, output_stream.getvalue()

# --- ã‚¢ãƒ—ãƒªç”»é¢ ---
st.title("ğŸ•µï¸ æ–‡å­—èµ·ã“ã—åŒ¿ååŒ–ãƒ„ãƒ¼ãƒ« v4")
st.markdown("""
ä»¥ä¸‹ã®æƒ…å ±ã‚’ä¸€æ‹¬ã§ `Speaker_X` ç­‰ã«å¤‰æ›ã—ã¾ã™ã€‚
* **åå‰**ï¼ˆä¼šè©±ã®ã€Œåå‰:ã€ï¼‰
* **è‹±å­—æ°å**ï¼ˆ`R.Okuzumi`, `X.Su` ãªã©ï¼‰
* **ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹**
* **ãƒ•ã‚¡ã‚¤ãƒ«åã®æ‹¬å¼§å†…ã®æ°å**

å¯¾å¿œå½¢å¼: `.txt`, `.md`, `.csv`, `.docx`
""")

uploaded_files = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True)

if uploaded_files:
    if st.button(f"{len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†é–‹å§‹"):
        progress_bar = st.progress(0)
        zip_buffer = io.BytesIO()
        processed_count = 0
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for i, file_obj in enumerate(uploaded_files):
                filename = file_obj.name
                ext = os.path.splitext(filename)[1].lower()
                
                if ext == '.docx':
                    new_name, new_data = process_docx_file(file_obj)
                else:
                    new_name, new_data = process_text_file(file_obj)
                
                if new_name and new_data:
                    zip_file.writestr(new_name, new_data)
                    processed_count += 1
                
                progress_bar.progress((i + 1) / len(uploaded_files))
        
        st.success(f"å®Œäº†ï¼ {processed_count} / {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿")
        st.download_button("ğŸ“¦ ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buffer.getvalue(), "anonymized_v4.zip", "application/zip")
